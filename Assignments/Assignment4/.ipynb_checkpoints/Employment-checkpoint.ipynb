{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State Space: $S={0,w1,....wn}$\n",
    "\n",
    "Action Space $A={reject,accept}$\n",
    "\n",
    "Transition function: P(s1,a,s2)\n",
    "1. if $s1\\neq 0$, $P(s1,a,0)=\\alpha$, $P(s1,a,s1)=\\alpha$\n",
    "2. if $s1=0$,$P(s1,accept,w_n)=p_n$ $P(s1,reject,0)=1$\n",
    "\n",
    "Reward function: R(s1,a,s2)=log(s1) if s1>0\n",
    "R(s1,a,s2)=0 if s1<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-d5fae6b3e4f7>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d5fae6b3e4f7>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    wages,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict,Mapping, Iterator\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.markov_decision_process import FinitePolicy, StateActionMapping\n",
    "from rl.markov_process import FiniteMarkovProcess, FiniteMarkovRewardProcess\n",
    "from rl.distribution import Categorical, Constant\n",
    "from scipy.stats import poisson\n",
    "from rl.dynamic_programming import value_iteration_result,value_iteration,almost_equal_vfs\n",
    "from rl.iterate import converged, iterate,converge\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Define the stateclass\n",
    "@dataclass(frozen=True)\n",
    "class SalaryState:\n",
    "    salary: int\n",
    "\n",
    "# 0 is A,1 is B\n",
    "SalaryStateMapping = StateActionMapping[SalaryState, int]\n",
    "\n",
    "\n",
    "class SimpleSalaryMDP(FiniteMarkovDecisionProcess[SalaryState, int]):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha:float\n",
    "        wages,\n",
    "        prob\n",
    "    ):\n",
    "        self.alpha:float=alpha\n",
    "        self.wages=wages\n",
    "        self.prob=prob\n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "    def get_action_transition_reward_map(self) -> SalaryStateMapping:\n",
    "        d: Dict[SalaryState, Dict[int, Categorical[Tuple[SalaryState,float]]]] = {}\n",
    "        d0=Dict[int,Categorical[Tuple[FrogState,float]]]={}\n",
    "        sr_probs_dict0:Dict[Tuple[SalaryState,float]]={}\n",
    "        sr_probs_dict1:Dict[Tuple[SalaryState,float]]={}\n",
    "        for i in range (len(wages)):\n",
    "            sr_probs_dict0[(SalaryState(0),0)]=1\n",
    "            sr_probs_dict1[(SalaryState(wages[i]),0)]=selg.prob[i]\n",
    "        d0[0]=Categorical(sr_probs_dict0)\n",
    "        d0[1]=Categorical(sr_probs_dict1)\n",
    "        d[SalaryState(0)]=d0\n",
    "        for i in range(len(wages)):\n",
    "            d1:Dict[int,Categorical[Tuple[FrogState,float]]]={}\n",
    "            for action in range(2):\n",
    "                sr_probs_dict:Dict[Tuple[SalaryState,float]]={}\n",
    "                sr_probs_dict[(SalaryState(0),math.log(wages[i]))]=self.alpha\n",
    "                sr_probs_dict[(FrogState(wages[i]),math.log(wages[i]))]=1-self.alpha\n",
    "                d1[action]=Categorical(sr_probs_dict)\n",
    "            d[SalaryState(i)]=d1\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
