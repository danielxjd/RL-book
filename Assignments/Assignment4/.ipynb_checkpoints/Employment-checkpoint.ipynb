{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State Space: $S={0,w1,....wn}$\n",
    "\n",
    "Action Space $A={reject,accept}$\n",
    "\n",
    "Transition function: P(s1,a,s2)\n",
    "1. if $s1\\neq 0$, $P(s1,a,0)=\\alpha$, $P(s1,a,s1)=\\alpha$\n",
    "2. if $s1=0$,$P(s1,accept,w_n)=p_n$ $P(s1,reject,0)=1$\n",
    "\n",
    "Reward function: R(s1,a,s2)=log(s1) if s1>0\n",
    "R(s1,a,s2)=0 if s1<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict,Mapping, Iterator\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.markov_decision_process import FinitePolicy, StateActionMapping\n",
    "from rl.markov_process import FiniteMarkovProcess, FiniteMarkovRewardProcess\n",
    "from rl.distribution import Categorical, Constant\n",
    "from scipy.stats import poisson\n",
    "from rl.dynamic_programming import value_iteration_result,value_iteration,almost_equal_vfs\n",
    "from rl.iterate import converged, iterate,converge\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Define the stateclass\n",
    "@dataclass(frozen=True)\n",
    "class SalaryState:\n",
    "    salary: int\n",
    "\n",
    "# 0 is A,1 is B\n",
    "SalaryStateMapping = StateActionMapping[SalaryState, int]\n",
    "\n",
    "\n",
    "class SimpleSalaryMDP(FiniteMarkovDecisionProcess[SalaryState, int]):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha:float,\n",
    "        wages,\n",
    "        prob\n",
    "    ):\n",
    "        self.alpha:float=alpha\n",
    "        self.wages=wages\n",
    "        self.prob=prob\n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "    def get_action_transition_reward_map(self) -> SalaryStateMapping:\n",
    "        d: Dict[SalaryState, Dict[int, Categorical[Tuple[SalaryState,float]]]] = {}\n",
    "        d0:Dict[int,Categorical[Tuple[SalaryState,float]]]={}\n",
    "        sr_probs_dict0:Dict[Tuple[SalaryState,float]]={}\n",
    "        sr_probs_dict1:Dict[Tuple[SalaryState,float]]={}\n",
    "        for i in range (len(self.wages)):\n",
    "            sr_probs_dict0[(SalaryState(0),0)]=1\n",
    "            sr_probs_dict1[(SalaryState(self.wages[i]),0)]=self.prob[i]\n",
    "        d0[0]=Categorical(sr_probs_dict0)\n",
    "        d0[1]=Categorical(sr_probs_dict1)\n",
    "        d[SalaryState(0)]=d0\n",
    "        for i in range(len(self.wages)):\n",
    "            d1:Dict[int,Categorical[Tuple[SalaryState,float]]]={}\n",
    "            for action in range(2):\n",
    "                sr_probs_dict:Dict[Tuple[SalaryState,float]]={}\n",
    "                sr_probs_dict[(SalaryState(0),math.log(self.wages[i]))]=self.alpha\n",
    "                sr_probs_dict[(SalaryState(self.wages[i]),math.log(self.wages[i]))]=1-self.alpha\n",
    "                d1[action]=Categorical(sr_probs_dict)\n",
    "            d[SalaryState(self.wages[i])]=d1\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=[1,2,3]\n",
    "prob=[0.2,0.3,0.5]\n",
    "si_mdp1=SimpleSalaryMDP(alpha=0.1,wages=salary,prob=prob)\n",
    "opt_vf_vi, opt_policy_vi = value_iteration_result(si_mdp1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{SalaryState(salary=0): 6.2524282258739845,\n",
       " SalaryState(salary=1): 2.961625384312576,\n",
       " SalaryState(salary=2): 6.609768439164322,\n",
       " SalaryState(salary=3): 8.743795323518912}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_vf_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "For State SalaryState(salary=0):\n",
       "  Do Action 1 with Probability 1.000\n",
       "For State SalaryState(salary=1):\n",
       "  Do Action 0 with Probability 1.000\n",
       "For State SalaryState(salary=2):\n",
       "  Do Action 0 with Probability 1.000\n",
       "For State SalaryState(salary=3):\n",
       "  Do Action 0 with Probability 1.000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_policy_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
